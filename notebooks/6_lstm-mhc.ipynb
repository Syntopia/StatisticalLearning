{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tQJd2YSCfWR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7tqLMoKF6uq"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 6\n",
    "------------\n",
    "\n",
    "After training a skip-gram model in `5_word2vec.ipynb`, the goal of this notebook is to train a LSTM character model over [Text8](http://mattmahoney.net/dc/textdata) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MvEblsgEXxrd"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 5993,
     "status": "ok",
     "timestamp": 1445965582896,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RJ-o3UBUFtCw",
    "outputId": "d530534e-0791-4a94-ca6d-1c8f1b908a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(filename):\n",
    "    filename, _ = urlretrieve(url + filename, filename)\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified %s' % filename)\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 5982,
     "status": "ok",
     "timestamp": 1445965582916,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "Mvf09fjugFU_",
    "outputId": "8f75db58-3862-404b-a0c3-799380597390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 3402339\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "  with zipfile.ZipFile(filename) as f:\n",
    "    name = f.namelist()[0]\n",
    "    data = tf.compat.as_str(f.read(name))\n",
    "  return data\n",
    "  \n",
    "text = read_data(\"d:/trump.zip\")\n",
    "print('Data size %d' % len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ga2CYACE-ghb"
   },
   "source": [
    "Create a small validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 6184,
     "status": "ok",
     "timestamp": 1445965583138,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "w-oBpfFG-j43",
    "outputId": "bdb96002-d021-4379-f6de-a977924f0d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3401339  new book, The Trump Card: http://tinyurl.com/ycsqmda\r\n",
      "\"A lot of\n",
      "1000 From Donald Trump: Wishing everyone a wonderful holiday & a happ\n"
     ]
    }
   ],
   "source": [
    "valid_size = 1000\n",
    "valid_text = text[:valid_size]\n",
    "train_text = text[valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zdw6i4F8glpp"
   },
   "source": [
    "Utility functions to map characters to vocabulary IDs and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 6276,
     "status": "ok",
     "timestamp": 1445965583249,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "gAL1EECXeZsD",
    "outputId": "88fc9032-feb9-45ff-a9a0-a26759cc1f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols found: 92\n",
      "Symbols: \n",
      "\r",
      " !\"#$%&'()+,-./0123456789:=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~ –‘’“”…\n",
      "29 29 2 29\n",
      "? Z 6\n"
     ]
    }
   ],
   "source": [
    "# MHC: This code was added by me, to support texts with an arbitrary set of characters\n",
    "\n",
    "letters = ''.join(sorted(set(text[0:100000])))\n",
    "lettersToIndex = {}\n",
    "\n",
    "for i in range(0, len(letters)):\n",
    "    lettersToIndex[letters[i]] = i \n",
    "\n",
    "questionMark = lettersToIndex['?']\n",
    "vocabulary_size = len(letters)\n",
    "    \n",
    "print(\"Symbols found: \" + str(len(letters)))\n",
    "print(\"Symbols: \" + letters)\n",
    "\n",
    "def char2id(char):\n",
    "  return lettersToIndex.get(char, questionMark)\n",
    "  \n",
    "def id2char(dictid):\n",
    "  return letters[dictid]\n",
    "\n",
    "\n",
    "print(char2id('Ø'), char2id('ø'), char2id(' '), char2id('ï'))\n",
    "print(id2char(char2id('Ø')), id2char(56), id2char(23))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFwoyygOmWsL"
   },
   "source": [
    "Function to generate a training batch for the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 6473,
     "status": "ok",
     "timestamp": 1445965583467,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "d9wMtjy5hCj9",
    "outputId": "3dd79c80-454a-4be0-8b71-4a4a357b3367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' new book, The Trump Card: http://tinyurl', 'nother....http://www.trump.com/Golf_Clubs', 'tate, local, and federal taxes.” #TimeToG', '\\nWhy does @BarackObama continue to defend', '’s ‘recovery’? http://t.co/laeI0SFA\\r\\n@Bar', 'ave traveled the world. America is the mo', 'ting America all of ours.\\r\\nFast and Furio', 'rnationally.\" - US Senator @BarackObama, ', 'bit.ly/ff8tRT\\r\\nCheck out ShouldTrumpRun..', 'ptcy.\\r\\n@derekwilkinson @daniellecfriel Th', ' performance was great last night--BQ wil', 'stakes but the good decisions and insight', ' Scottish course are already double our p', 'ove to have my ratings?\\r\\nThe only thing m', '-not very professional.\\r\\nWe should not al', 'Stunt\\'\" http://t.co/KY2wgyz4 via @eonline', 'nings to attack, especially when Obama st', 'p? how destructive they are. Windmills ar', 's until the election. How many illegal do', 'election than his @nyjets win games shows', 'have many times over.\\r\\n\"Amazing Race\" win', 'worst President we have ever had.\\r\\nWe thr', 'e to make a great deal with Iran.\\r\\n.@GovM', \"a's background. I, for one, won't be.\\r\\nIt\", 'kObama hiding?\\r\\nThe Penn State Board shou', 'ison\\r\\nWhy has @BarackObama allowed the Mu', \"ds (like other Presidents)....\\r\\nDon't bel\", 'rt politics!\\r\\nWatch the WH spokesman try ', \"Now that China's own economy is slowing h\", 'ht- live Season Finale at 9PM ET on NBC.\\r', 'ent numbers are terrible. 522,000 more pe', ' event in Trump Tower last week- http://t', 'ol--a 78% increase in 10 years. Stop givi', 'e... http://t.co/Kx83LkkS\\r\\nMy @SquawkCNBC', 'tp://t.co/iuwrAOj3\\r\\nMy robocall on behalf', 'Trump Bike that Paul Teutul Sr. presented', ' Romney \"George\" (Mitt\\'s father). Sadly, ', 'illion American funded Finnish plug in ca', 'comed to relax at Hawaii’s top hotel @Tru', 'illyHallowell:“DONALD TRUMP BLASTS OBAMA ', 'ill always find a philosophy to justify i', 't Obama is finally getting hammered, even', ' is losing.” - Vince Lombardi\\r\\nAgain, mor', \"sand.” – Milton Friedman\\r\\n@Rizz_Lizz You'\", ' tax, Boston Scientific plans to cut 1,50', 'inst the renewable energy agenda! See, I ', \"on't pat yourself on the back, nobody els\", 'ing day in Dubai! Launch of the #Trump Es', ' at all times. Achievement is not a plate', 'vivor #Apprentice\"\\r\\nThe Emmys are sooooo ', 'test. To everyone who hates on him, HE DO', 'eatest.. Thank you. #staygreat!\"  I will ', '\\r\\n\"@seanofkbio: @TrumpGolfLinks @realDona', 'elf.” – Think Big\\r\\nWith the signature ser', ' Weiner is dead in his race for mayor of ', 'is without a doubt ---political.\"\\r\\n\"@robe', 'p @NY_POLICE then Donald will be OK being', 'ust listen http://t.co/b7v6WVy5Kh @TheRig', 'rump warned for a year now about windfarm', 'by Russia.\\r\\n@THETylerDeBoer @JoelOsteen  ', \"IvankaTrump @realDonaldTrump Can't wait! \", ' about Eliot Spitzer? Will you say the sa', 'hNorville: It is sooo hot in New York tod', \": If you don't follow @realDonaldTrump yo\", \"Trump _ He's a foreign pilot. We couldn't\", 'e!\\r\\n\"@MikeDGarrison: \"Judge orders Miss P', 'ident.\"  Thank you!\\r\\n\"@jerrimoore: @realD', 'JLLeonard Thanks!\\r\\nDue diligence includes', 'vanka is a great daughter!\\r\\n\"@Tigergal62:', '@arid93  They should have stopped paying ', 'realDonaldTrump people hate you because t', 'ne, run for president already #america\"  ', 'realDonaldTrump @bluejoni like your golf ', 'ec.\\r\\nGeneral says that the Armed Forces w', 'kes maintenance &amp? planning to grow.\\r\\n', 'rump Jon Stewart calls you F??ckface Von ', ' The only problem is that... http://t.co/', 'y role models.\" Thanks!\\r\\n\"@NeilWhinhamPGA', 'oom? #CelebApprentice\\r\\nGeorge also appear', ': @realDonaldTrump Mr. Trump what keeps y', 'pers that would implicate him re. drugs -', 'I will be posting exclusive behind the… h', ' he apologizing for? Steve Jobs wouldn’t.', 'n that @NYMag has become so boring and so', 'orking hard.\" Think Big\\r\\nI hope everyone ', 'use tours.\" http://t.co/48iaCr3YSC\\r\\nCongr', 'd!\" Thanks, really nice!\\r\\n\"@RealJonJenkin', \" won't backstab-she'll come at you from t\", 'ost: @realDonaldTrump Esquire is irreleva', 's him, it hurts the church...\\r\\n...and say', 'ony. Next Sunday!\\r\\n@farm_mom. True.\\r\\nI ho', '_grunch @Joan_Rivers @ApprenticeNBC  Seri', 'golf tournament today!\\r\\nGood luck @RoccoM', 'BC\\r\\n.@marklevinshow has been saying very ', 'should assume.\\r\\n@Kevin_Johnson68 @trapass', 'Rose should now be in the Baseball Hall O', 'may not grow from trees, but it does grow', ' deal for the country and an embarrassmen', 'nk you.\\r\\n\"@randallburton20: @realdonaldtr', 'ay be garbage but we can’t let a foreign ', 'clear_King: @realDonaldTrump #Trump2016\"\\r', 'sie yet.\" They will, soon!\\r\\n.@GolfMagazin', 'that he\\'s running for President\"\\r\\n\"@Kaela', ' rule lk beyond expectation! ????\"\\r\\n\"@Big', ' Trump. #SmackDown #yourefired http://t.c', 'l @jstines3 @Po_st Trump is an American C', ': \"@realDonaldTrump: \"@heelshoops23: @rea', 'hannel\\r\\n\"@CRinQC: Hates military. Tues, r', 'sort traveler for life!\" Great and thanks', 'harton School of Finance. The Joseph Whar', 'in Ireland” - @realDonaldTrump tells News', 're.. Run so we get someone in the office ', \"right, you're right. If you were Presiden\", 'tp://t.co/MCePJwuG1U\"  Thank you!\\r\\n\"@Cort', 'axes way too high, roads in terrible cond', 'ft years ago. I had the big boxing, intro', ' joan rivers very happy when u rightfully', 'lDonaldTrump! Personally I had no doubts ', \"mpkin: You're the man.We need you as our \", 'oor-to-ceiling windows providing unparall', \"sly thought, AND IT DOESN'T WORK! Big tro\", 'r difficulties are so easy to solve!\\r\\n@La', \"stop vacationing. Gov't will save million\", ' O regime &amp? @gop cowards.\" That\\'s wha', 'merson\\r\\n\"If you want to be successful, tw', 'hicago on a business trip. I love seeing ', 'rump Great job!\\r\\n\"@Domeski1981: @GraemeRe', 'dTrump comes on. He is so refreshingly ho', 'atching paint dry #USOpen #anticlimax\"\\r\\n\"', 'ure everyone can see that name!\"\\r\\n\"@Majes', 'the Miss USA Pageant will be shown live o', 'aldTrump please run for president to save', 'nue to Think Big and you will be able to ', 'n for president.We need your help. Get in', \"of the course @ #Trump Int'l #Golf Club w\", 'ommish\\r\\n\"@kimkardarshian3: @realDonaldTru', 'MadG0d: Buffalo has one great Donald Trum', 'ng by @realDonaldTrump is truly inspiring', '16! We need a REAL leader who wont put up', 'good luck!\\r\\n\"@dalasner @realDonaldTrump L', '\\nPresident Obama looks absolutely exhaust', 'ing to Baton Rouge in June.\"\\r\\n\"@ellentime', 'lling it with the #oscars tweet.\"\\r\\n\"@john', 'rica will be saved-ith and all will be we', ' @TrumpSoHo My wife and I stayed there an', 'Trump is our future. Only he can turn our', 'gs next Tuesday. See you in Manchester! #', 'an               \\r\\n@realDonaldTrump when ', 'ush when he is so low in the polls?\" Beca', 'ruz kids. Bad\\r\\nThe silent majority- is si', '\\r\\n\"@DonaldTrumpFink: .@GovMikeHuckabee: I', 'ing ready to attack. I am leading by so m', 'ightful tweets. Make them good (great)! I', 'mmigrant children, non-Mexicans surge acr', ' Wish I could get @OANN I hear good thing', 'th Carolina! See you next Tuesday! #MakeA', 'utin?never said I was in Green Room. Sepa', \"snl: We're live from Studio 8H tonight. #\", 'oin me tomorrow, Nov. 3rd, at 12pm in #Tr', 'Thank you! https://t.co/7JBjeWt6XK\\r\\nJoin ', 'join up and work together on Twitter! Let', 'l at 28 percent in N.H.\"  https://t.co/gX', 'nityFair Magazine, \"Sloppy\" Graydon Carte', 'Trump Is Tops As Clinton Drops In Connect', 'no power,  but so dishonest!\\r\\nI wonder wh', 'ging @MontesKitchen in upstate, New York.', \"at I won't be doing any more Fox shows fo\", ' their money. ON the BORDER and IMMIGRATI', 'ld has already done many great things,he ', '@BenFergusonShow just watched you on @CNN', ' best Immigration Policy yet! Time for @r', 'dTrump show. Projected to be the most wat', \" P.B. Club), but I don't want their money\", 'athway for illegals\"\\r\\n\"@dc1a7ce3d7f7402: ', ' to publish one of my old cell phone numb', 's are heroes!\\r\\nIn addition to doing a lou', 'py eyes @chucktodd will be fired like a d', ', we win in a landslide.\\r\\n\"@hallmarkm1 @r', ' support @realDonaldTrump and I as well w', 'nessman.\\r\\n\"@TheHolyBreadcat: @realDonaldT', 'nchester, NH  #MakeAmericaGreatAgain!\\r\\nTh', 'ted to vote for @realDonaldTrump since I ', 'iLMv2vOez7\\r\\n\"@GaryWhalenTV A pleasure to ', '\\r\\n\"@JollyGoodman181: Vote Trump for Presi', \"ut they had Give'm Hell Harry for Pres...\", 'RESIDENT!\" Stay tuned!\\r\\n\"@AlexPascal123: ', ' or July 4th. #Symbolism #Patriotic #GoBi', 'H Barrington Middle School! Thanks to @st', 'The United States needs great deals - and', 'G BUT I LOVE THE WAY HE CAN TALK&amp?RUN ', 'ying for you, the Mexico situation and yo', 'p. Please run for President. We need a co', 'Thanks.\\r\\n\"@bluebirdiefly3: @realDonaldTru', '/UpURDegT8H\\r\\nToday is April 15th, Obama’s', '! ???? #TeamAmerica\"\\r\\n\"@LouistheXVI99: @r', 'wa - great people, great state!\\r\\n\"@Colema', 'nd you hit it on the head, bring all manu', 'ial candidacy &amp? making America great ', 'by celebrated design house Fendi Casa and', ' Thanks!\\r\\n\"@Budd0427 @realDonaldTrump Jea', ' Oscars and the ratings will zoom. Also, ', 'be a true leader.\"\\r\\n\"@carriejo4ever: @rea', 'ealDonaldTrump: \"@stephanienap5: @realDon', 'tice With three wonderful, but fired, con', 'g out of the race?looks like he won’t be ', 'ou need it?\" I dearly hope you are able t', '@realDonaldTrump @LandExpo no wonder you ', 'tice\"\\r\\n\"@RealityTVBliss: Tune into #Celeb', ' Sir so enjoyed Appren tonight tears in e', 'nks.\\r\\n\"@Christ_Step: @realDonaldTrump 201', '\"@AliceSLeuck: @ApprenticeNBC Join the le', 'ear! Thanks for a great show. Got out of ', \" can't wait to watch @BrandiGlanville dom\", 'this country around\"  I do, big league!\\r\\n', 'morrow! #MAGA \\r\\n10am- Baton Rouge, LA. \\r\\n', 'ntial award because as President I have t', 'https://t.co/k5kGXPR2WA\"\\r\\n\"@Ravenrantz: #', 'ARLY VOTING BY FL. COUNTY:… https://t.co/', 'x hikes will CRUSH our economy. I will cu', 'n Campaign, may poison the minds of the A', ' Juanita Broaddrick Relives Brutal Rapes:', 'id you see how badly @CNN (Clinton News N', 'today at https://t.co/3KWOl2ibaW. https:/', 's://t.co/RmQJt0Wxcq\\r\\nJoin me in Pensacola', 'eech is pandering to the worst instincts ', 'ay by the NYPD in protecting the people a', '! https://t.co/4LnzfKRsqZ\\r\\nLIMITED EDITIO', 'ttps://t.co/rSEcsjiNFb\\r\\nhttps://t.co/ybFO', ' I saw his speech two hours early but let', 'Off to Washington D.C. now. #Trump2016 #A', ' is time for CHANGE -- and JOBS!\\r\\nTop 50 ', 'ting? They were cheering all over, even t', 'cans in Benghazi?  https://t.co/ZV5ehm6NK', 'lion dollars from me, for our VETERANS. N', 'use there were so many positive statement', 'ants to destroy all miners, I want wages ', 'olutely killing our country. Stop them no', 'mh3iSPBY\" Thank you!\\r\\n\"@vivhall3: @realDo', '!\\r\\n\"@PaulaDuvall2:  Cruz will say anythin', '\"@saneplanet: after tonight it is clear! ', 'be allowed to compete in Ohio on Tue.\\r\\nCa', 'and paid for!\\r\\nGreat time last night in L', 'ps://t.co/evoiSpn8PX\\r\\nIncredibly proud of', ' video @IvankaTrump created on \"How to Ca', 'SC\\r\\nThank you, South Carolina! #MakeAmeri', 'day! #VoteTrumpNH \\r\\nVideo: https://t.co/7', 'ed my long-shot great finish in Iowa fair', 'owers all the times he asked for him and ', ' pipelines.\\r\\nRT @williebosshog: Make Amer', 'our support last night, Iowa! #VoteTrump ', '/me, he would’ve been in the playoffs, at', 'RuQZZHrc\\r\\nThank you Sean McGarvey &amp? t', '\\nMeeting w/ Washington, D.C. @MayorBowser', 't.co/OigfXFECPp\\r\\nWelcome to the United St', 'merican dream is back. We’re going to cre', 'auguration Day is turning out to be even ']\n",
      "['Fr']\n",
      "['ro']\n"
     ]
    }
   ],
   "source": [
    "batch_size=64*4\n",
    "num_unrollings=40\n",
    "\n",
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, num_unrollings):\n",
    "    self._text = text\n",
    "    self._text_size = len(text)\n",
    "    self._batch_size = batch_size\n",
    "    self._num_unrollings = num_unrollings\n",
    "    segment = self._text_size // batch_size\n",
    "    self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "    self._last_batch = self._next_batch()\n",
    "  \n",
    "  def _next_batch(self):\n",
    "    \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
    "    batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\n",
    "    for b in range(self._batch_size):\n",
    "      batch[b, char2id(self._text[self._cursor[b]])] = 1.0\n",
    "      #print(self._text[self._cursor[b]])\n",
    "      #print(ord(self._text[self._cursor[b]]))\n",
    "      #print(\"C:\" + str(char2id(self._text[self._cursor[b]])))\n",
    "        \n",
    "      self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "    return batch\n",
    "  \n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "    the last batch of the previous array, followed by num_unrollings new ones.\n",
    "    \"\"\"\n",
    "    batches = [self._last_batch]\n",
    "    for step in range(self._num_unrollings):\n",
    "      batches.append(self._next_batch())\n",
    "    self._last_batch = batches[-1]\n",
    "    return batches\n",
    "\n",
    "def characters(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  characters back into its (most likely) character representation.\"\"\"\n",
    "  return [id2char(c) for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "  \"\"\"Convert a sequence of batches back into their (most likely) string\n",
    "  representation.\"\"\"\n",
    "  s = [''] * batches[0].shape[0]\n",
    "  for b in batches:\n",
    "    s = [''.join(x) for x in zip(s, characters(b))]\n",
    "  return s\n",
    "\n",
    "train_batches = BatchGenerator(train_text, batch_size, num_unrollings)\n",
    "valid_batches = BatchGenerator(valid_text, 1, 1)\n",
    "\n",
    "batch = np.zeros(shape=(10, vocabulary_size), dtype=np.float)\n",
    "\n",
    "\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(valid_batches.next()))\n",
    "print(batches2string(valid_batches.next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KyVd8FxT5QBc"
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "  \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "  predictions[predictions < 1e-10] = 1e-10\n",
    "  return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "  \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "  probabilities.\n",
    "  \"\"\"\n",
    "  r = random.uniform(0, 1)\n",
    "  s = 0\n",
    "  for i in range(len(distribution)):\n",
    "    s += distribution[i]\n",
    "    if s >= r:\n",
    "      return i\n",
    "  return len(distribution) - 1\n",
    "\n",
    "def sample(prediction):\n",
    "  \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "  p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
    "  p[0, sample_distribution(prediction[0])] = 1.0\n",
    "  return p\n",
    "\n",
    "def random_distribution():\n",
    "  \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "  b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
    "  return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8f67YXaDr4C"
   },
   "source": [
    "Simple LSTM Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Q5rxZK6RDuGe"
   },
   "outputs": [],
   "source": [
    "num_nodes = 64*2\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  # Parameters:\n",
    "  # Input gate: input, previous output, and bias.\n",
    "  ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ib = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Forget gate: input, previous output, and bias.\n",
    "  fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  fb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Memory cell: input, state and bias.                             \n",
    "  cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  cb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Output gate: input, previous output, and bias.\n",
    "  ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ob = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Variables saving state across unrollings.\n",
    "  saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  # Classifier weights and biases.\n",
    "  w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n",
    "  b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "  \n",
    "  # Definition of the cell computation.\n",
    "  def lstm_cell(i, o, state):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    return output_gate * tf.tanh(state), state\n",
    "\n",
    "  # Input data.\n",
    "  train_data = list()\n",
    "  for _ in range(num_unrollings + 1):\n",
    "    train_data.append(\n",
    "      tf.placeholder(tf.float32, shape=[batch_size,vocabulary_size]))\n",
    "  train_inputs = train_data[:num_unrollings]\n",
    "  train_labels = train_data[1:]  # labels are inputs shifted by one time step.\n",
    "\n",
    "  # Unrolled LSTM loop.\n",
    "  outputs = list()\n",
    "  output = saved_output\n",
    "  state = saved_state\n",
    "  for i in train_inputs:\n",
    "    output, state = lstm_cell(i, output, state)\n",
    "    outputs.append(output)\n",
    "\n",
    "  # State saving across unrollings.\n",
    "  with tf.control_dependencies([saved_output.assign(output),\n",
    "                                saved_state.assign(state)]):\n",
    "    # Classifier.\n",
    "    logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.concat(train_labels, 0), logits=logits))\n",
    "\n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "    10.0, global_step, 5000, 0.5, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "  gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "  optimizer = optimizer.apply_gradients(\n",
    "    zip(gradients, v), global_step=global_step)\n",
    "\n",
    "  # Predictions.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "  # Sampling and validation eval: batch 1, no unrolling.\n",
    "  sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n",
    "  saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  reset_sample_state = tf.group(\n",
    "    saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "    saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "  sample_output, sample_state = lstm_cell(\n",
    "    sample_input, saved_sample_output, saved_sample_state)\n",
    "  with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "                                saved_sample_state.assign(sample_state)]):\n",
    "    sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 41
      },
      {
       "item_id": 80
      },
      {
       "item_id": 126
      },
      {
       "item_id": 144
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 199909,
     "status": "ok",
     "timestamp": 1445965877333,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RD9zQCZTEaEm",
    "outputId": "5e868466-2532-4545-ce35-b403cf5d9de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 4.528353 learning rate: 10.000000\n",
      "Minibatch perplexity: 92.61\n",
      "================================================================================\n",
      "sz\"s’xUL NO~Gnw”tIigP _VLX16Mt)yy9'Agqb7P”I“K~FMFod\n",
      "hNlOFW4…H“A./5TW0+L%mhC6…Aq5\n",
      "&gPMohG~8:S WO’,!j!d-X\n",
      "CAAfm?bPQ$a%(“9_4P7\n",
      "#’k'–G\n",
      "y:G\"!6\n",
      "‘9f%2tc Yym%JahX'TQx ~yzEA5G/1PVQg\n",
      " sBax@(x3B\"–#x:~z9E'zc7xyy\n",
      "ZQsuK~-)9GNI_U!K+j…fEnlrl4YY7=28AqhA1hz0V‘C_2iHpu? &OCj.ME#% j96@R# -v2–6 7V(s Q\n",
      "@FKSm ?FgaUADa…H@H0_TLzLjHU#7bB\"9T#wrA‘pM0u.IV!ZcdH8Qz‘3k:83S\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 94.54\n",
      "Average loss at step 100: 3.542754 learning rate: 10.000000\n",
      "Minibatch perplexity: 27.54\n",
      "Validation set perplexity: 27.82\n",
      "Average loss at step 200: 3.136698 learning rate: 10.000000\n",
      "Minibatch perplexity: 19.35\n",
      "Validation set perplexity: 18.42\n",
      "Average loss at step 300: 2.745489 learning rate: 10.000000\n",
      "Minibatch perplexity: 12.95\n",
      "Validation set perplexity: 13.98\n",
      "Average loss at step 400: 2.528569 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.75\n",
      "Validation set perplexity: 12.55\n",
      "Average loss at step 500: 2.392558 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.29\n",
      "Validation set perplexity: 11.94\n",
      "Average loss at step 600: 2.299470 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.03\n",
      "Validation set perplexity: 11.56\n",
      "Average loss at step 700: 2.227876 learning rate: 10.000000\n",
      "Minibatch perplexity: 9.28\n",
      "Validation set perplexity: 10.65\n",
      "Average loss at step 800: 2.159370 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.50\n",
      "Validation set perplexity: 10.14\n",
      "Average loss at step 900: 2.107058 learning rate: 10.000000\n",
      "Minibatch perplexity: 8.43\n",
      "Validation set perplexity: 9.98\n",
      "Average loss at step 1000: 2.071672 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.85\n",
      "================================================================================\n",
      "… not if last and buch as &amp? A4 adbacks mud Bow and http://t.co/tzDGGmhuPC01 \n",
      "IS\"  U6 how hist a jol need: I Am_P’sion otery.:\n",
      "\"@CuCniderudefuedhaia41p: @amp\n",
      "-\"2BI, Ris tode fite Bring thlinive or it to hit &amp? whe Turd is a Sozent ot t\n",
      "–.\"  Heay nith grig tim to gesers. vot a wisd for so who rigation smum) Chike of\n",
      "20 http:/'t.co/Jz5RCppN\n",
      "@serddChed cacid sey the every al evenatimy hepher, od \n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 10.32\n",
      "Average loss at step 1100: 2.034892 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.43\n",
      "Validation set perplexity: 9.09\n",
      "Average loss at step 1200: 1.987928 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.35\n",
      "Validation set perplexity: 8.64\n",
      "Average loss at step 1300: 1.963692 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.87\n",
      "Validation set perplexity: 8.77\n",
      "Average loss at step 1400: 1.941361 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.93\n",
      "Validation set perplexity: 8.38\n",
      "Average loss at step 1500: 1.903476 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.42\n",
      "Validation set perplexity: 7.81\n",
      "Average loss at step 1600: 1.884327 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.34\n",
      "Validation set perplexity: 7.82\n",
      "Average loss at step 1700: 1.871048 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.46\n",
      "Validation set perplexity: 7.59\n",
      "Average loss at step 1800: 1.839994 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.04\n",
      "Validation set perplexity: 7.32\n",
      "Average loss at step 1900: 1.817176 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.93\n",
      "Validation set perplexity: 7.23\n",
      "Average loss at step 2000: 1.810299 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.07\n",
      "================================================================================\n",
      "70 is the Dest Inst all my cregnimane! love #Trump2016\" what is Trump 4meniseby.\n",
      "‘ VewAGruse and tough.\n",
      "Pub Carmen Jest. by watired onee que Ollegay reduceds di\n",
      "ckmenick’s Centery world algay kids, and @BaraRonyware.\n",
      "\"@Grikliaroo: Greattend\n",
      "jown news muches?\n",
      "\"@ctheilyrouali_Trump @BrealDonaldTrump pimpsenca)!\"I' @Barac\n",
      "hass.\n",
      "Mania What is thime deal who @Irrandas #Trump2016..https://t.co/5ioP5SbtP\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 6.98\n",
      "Average loss at step 2100: 1.794666 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.84\n",
      "Validation set perplexity: 6.63\n",
      "Average loss at step 2200: 1.771019 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.85\n",
      "Validation set perplexity: 7.56\n",
      "Average loss at step 2300: 1.764539 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.74\n",
      "Validation set perplexity: 7.25\n",
      "Average loss at step 2400: 1.753731 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.63\n",
      "Validation set perplexity: 6.51\n",
      "Average loss at step 2500: 1.732982 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.57\n",
      "Validation set perplexity: 6.69\n",
      "Average loss at step 2600: 1.723288 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.83\n",
      "Validation set perplexity: 6.74\n",
      "Average loss at step 2700: 1.722933 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.55\n",
      "Validation set perplexity: 6.24\n",
      "Average loss at step 2800: 1.702106 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.43\n",
      "Validation set perplexity: 6.23\n",
      "Average loss at step 2900: 1.688692 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.20\n",
      "Validation set perplexity: 6.36\n",
      "Average loss at step 3000: 1.692461 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.69\n",
      "================================================================================\n",
      "300s vote thair Reen Is a great gear life.\"\n",
      "\"@PIHA: contentute of my majon what\n",
      "xbonders, @realDonaldTrump in @Sreplinnarsi like BrapQendo, is get'rilly to in w\n",
      "illyY has buile and @realDonaldTrump wordd for America Clipserman for - HAU.OSE \n",
      "\n",
      "\"@sdrurc3700032: @mevingbopers Elleg\n",
      "\"@Bandny_mornuzon weesern till do buyly.\n",
      "genco will be at @ApprenticeNGC.\n",
      "\"@hirerautybatrol: @realDonaldTrump Tear Shatr\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 6.12\n",
      "Average loss at step 3100: 1.680233 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.26\n",
      "Validation set perplexity: 5.92\n",
      "Average loss at step 3200: 1.663178 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.45\n",
      "Validation set perplexity: 6.07\n",
      "Average loss at step 3300: 1.664187 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.27\n",
      "Validation set perplexity: 6.27\n",
      "Average loss at step 3400: 1.659939 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.06\n",
      "Validation set perplexity: 5.87\n",
      "Average loss at step 3500: 1.641442 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.29\n",
      "Validation set perplexity: 5.75\n",
      "Average loss at step 3600: 1.638848 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.05\n",
      "Validation set perplexity: 5.84\n",
      "Average loss at step 3700: 1.642014 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.11\n",
      "Validation set perplexity: 5.71\n",
      "Average loss at step 3800: 1.625882 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.05\n",
      "Validation set perplexity: 5.60\n",
      "Average loss at step 3900: 1.616908 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.14\n",
      "Validation set perplexity: 5.68\n",
      "Average loss at step 4000: 1.622105 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.21\n",
      "================================================================================\n",
      " Wook) him on sty work! This can't man for President last gain live it to stop! \n",
      "  – for cCC not spent an assolrient - http://t.co/Iy4H35btGm\n",
      "What a stond to mo\n",
      "lassly New Swevi NH over Parlas and more to say it hupt Me AUS EAL on Edma Am  W\n",
      "Chico and vote do \"Apbree hith CABK, outings to the Eunning GRETMHADRORDEM AMERI\n",
      "9 EET. as sont trump tones. If Hillary's will be wonder: http://t.co/9tSbIvufxV\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 5.65\n",
      "Average loss at step 4100: 1.613147 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.96\n",
      "Validation set perplexity: 5.53\n",
      "Average loss at step 4200: 1.600724 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.10\n",
      "Validation set perplexity: 5.52\n",
      "Average loss at step 4300: 1.602710 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.02\n",
      "Validation set perplexity: 5.69\n",
      "Average loss at step 4400: 1.601701 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.83\n",
      "Validation set perplexity: 5.46\n",
      "Average loss at step 4500: 1.587882 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.73\n",
      "Validation set perplexity: 5.65\n",
      "Average loss at step 4600: 1.588326 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.96\n",
      "Validation set perplexity: 5.59\n",
      "Average loss at step 4700: 1.591593 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.05\n",
      "Validation set perplexity: 5.38\n",
      "Average loss at step 4800: 1.577162 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.13\n",
      "Validation set perplexity: 5.55\n",
      "Average loss at step 4900: 1.570139 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.86\n",
      "Validation set perplexity: 5.51\n",
      "Average loss at step 5000: 1.577002 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.74\n",
      "================================================================================\n",
      ": @RTCER PORSTRON!  #ANGrante &amp? all proude. @rvattolroy devi tirnd, Mexico. \n",
      "Q TRUMP we as vote to year! Thank you Evaiats and bream, a this's placed and my \n",
      "% Alway- immigration with anyone!\n",
      "@rmylegtys2  Thanks-\n",
      "@realbroode8   Moson Fi\n",
      "/KATE BYAM AN LREUVickIGS\n",
      "17%riongtorich had should were someheprepial add figh\n",
      "Maring\n",
      "http://t.co/J09TeBEDaV\n",
      "Looking forward to Apperats?\n",
      "\"@Applezes @realDo\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 5.25\n",
      "Average loss at step 5100: 1.557337 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.51\n",
      "Validation set perplexity: 5.32\n",
      "Average loss at step 5200: 1.545882 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.79\n",
      "Validation set perplexity: 5.32\n",
      "Average loss at step 5300: 1.550131 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.79\n",
      "Validation set perplexity: 5.40\n",
      "Average loss at step 5400: 1.551721 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.67\n",
      "Validation set perplexity: 5.29\n",
      "Average loss at step 5500: 1.541543 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.67\n",
      "Validation set perplexity: 5.27\n",
      "Average loss at step 5600: 1.543073 learning rate: 5.000000\n",
      "Minibatch perplexity: 5.01\n",
      "Validation set perplexity: 5.33\n",
      "Average loss at step 5700: 1.550604 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.61\n",
      "Validation set perplexity: 5.23\n",
      "Average loss at step 5800: 1.537459 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.63\n",
      "Validation set perplexity: 5.28\n",
      "Average loss at step 5900: 1.534004 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.82\n",
      "Validation set perplexity: 5.22\n",
      "Average loss at step 6000: 1.542452 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.79\n",
      "================================================================================\n",
      "news but fun.\n",
      "Bey price to take and @Erphacoball Anyon I'm a grals from an ever\n",
      "con. Under Net has much usean U\n",
      "Mar-agen @annevicolroy GFOsfolt, reso you them! \n",
      "…..\"Donald Trump: Your fun hosted to #trump2016\"  http://www.....'&amp? They Oba\n",
      "!\n",
      "\"@chullmav204Mad: I feel smcon, I want @greta Championship, Now Arur. Sorabla\n",
      ": @soolfichalter run!\n",
      "NO On.I trilikious the happy now!! Enjoy!\n",
      "Dame @Hollefch\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 5.08\n",
      "Average loss at step 6100: 1.537733 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.62\n",
      "Validation set perplexity: 5.16\n",
      "Average loss at step 6200: 1.528626 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.64\n",
      "Validation set perplexity: 5.13\n",
      "Average loss at step 6300: 1.533691 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.62\n",
      "Validation set perplexity: 5.21\n",
      "Average loss at step 6400: 1.537179 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.72\n",
      "Validation set perplexity: 5.13\n",
      "Average loss at step 6500: 1.523776 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 5.21\n",
      "Average loss at step 6600: 1.529209 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.55\n",
      "Validation set perplexity: 5.13\n",
      "Average loss at step 6700: 1.535794 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.61\n",
      "Validation set perplexity: 5.11\n",
      "Average loss at step 6800: 1.520481 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 5.15\n",
      "Average loss at step 6900: 1.520225 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.60\n",
      "Validation set perplexity: 5.12\n",
      "Average loss at step 7000: 1.528827 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.64\n",
      "================================================================================\n",
      "\n",
      "@RICHamTiton: Donald Trump trump  /Sable.\n",
      "That's all the get neededation.\n",
      "I \n",
      "“Trump of #2020 has because of the potent cogulities #MGOMI has dopld nice.\n",
      "\"@J\n",
      "coms ‘Araza \"Big Jailed innow we suestified Touchalo, when he complication\"\n",
      "\"@G\n",
      " http://t.co/QDRYIFhM06\n",
      "Its I mush coppres to always having pirmore. Sirst for \n",
      "chert #scual’s Jabior?\n",
      "I'm a big croyately hard me to during it idnigity for th\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.96\n",
      "Average loss at step 7100: 1.522849 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.57\n",
      "Validation set perplexity: 5.08\n",
      "Average loss at step 7200: 1.515442 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.63\n",
      "Validation set perplexity: 5.14\n",
      "Average loss at step 7300: 1.520144 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.64\n",
      "Validation set perplexity: 5.24\n",
      "Average loss at step 7400: 1.522756 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 5.05\n",
      "Average loss at step 7500: 1.511402 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.54\n",
      "Validation set perplexity: 5.18\n",
      "Average loss at step 7600: 1.515767 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 5.16\n",
      "Average loss at step 7700: 1.523482 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.61\n",
      "Validation set perplexity: 4.99\n",
      "Average loss at step 7800: 1.508588 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 5.13\n",
      "Average loss at step 7900: 1.508219 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.57\n",
      "Validation set perplexity: 5.02\n",
      "Average loss at step 8000: 1.515904 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.51\n",
      "================================================================================\n",
      "#TrumpFrimars is an in Rince on Sitahic!\n",
      "Toway to me?\"  I wonder what dre turn \n",
      "(I'm Zill Snowder! The trump amorg!\n",
      "@willia @MilleOns “Sad a delevents, @PHST w\n",
      "_Whited will, a frott with (protectiving birthday at any to possed when expectmi\n",
      "Q Just follow Power \"to trump and official rene-bire.\"\n",
      "\"@rustisy: @realDonaldTr\n",
      "9 will be on FESTAHE and debate since touflam great man-fain!\" Thanks\n",
      "Just gony\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.93\n",
      "Average loss at step 8100: 1.511022 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.55\n",
      "Validation set perplexity: 4.97\n",
      "Average loss at step 8200: 1.502969 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 5.03\n",
      "Average loss at step 8300: 1.508848 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 5.03\n",
      "Average loss at step 8400: 1.512215 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 4.98\n",
      "Average loss at step 8500: 1.499018 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.70\n",
      "Validation set perplexity: 5.04\n",
      "Average loss at step 8600: 1.504650 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.53\n",
      "Validation set perplexity: 5.06\n",
      "Average loss at step 8700: 1.512186 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 8800: 1.497665 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 4.98\n",
      "Average loss at step 8900: 1.498602 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.49\n",
      "Validation set perplexity: 4.97\n",
      "Average loss at step 9000: 1.506556 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.62\n",
      "================================================================================\n",
      "x),0,000 again to count the runs airspersity inviligen: Mayagleake in the next n\n",
      "! https://t.co/Bq8HNcxv4w\n",
      "China would be surpress to chassional president. Dopa\n",
      " ....\"A truth.\n",
      "\"@haralGlayegally: @FoxNews http://t.co/GaBGcPcig2 Very the dris\n",
      "Chitical Deg--@todan cromes, Team! did you! I will be nice. What you need your t\n",
      "arted becams: I will be on you! #MakeAmericaGreatAgain https://t.co/RN7KIOGNzp\n",
      "\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 9100: 1.499502 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 4.97\n",
      "Average loss at step 9200: 1.491481 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 5.01\n",
      "Average loss at step 9300: 1.500419 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 5.01\n",
      "Average loss at step 9400: 1.501468 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 4.98\n",
      "Average loss at step 9500: 1.490144 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.54\n",
      "Validation set perplexity: 4.97\n",
      "Average loss at step 9600: 1.494933 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 5.07\n",
      "Average loss at step 9700: 1.501734 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.20\n",
      "Validation set perplexity: 4.93\n",
      "Average loss at step 9800: 1.489525 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 9900: 1.488986 learning rate: 5.000000\n",
      "Minibatch perplexity: 4.60\n",
      "Validation set perplexity: 4.99\n",
      "Average loss at step 10000: 1.497765 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.52\n",
      "================================================================================\n",
      "Japleig United Starts http://t.co/deQ9xpkR86 @CPolly Links etiloting 1131. Four \n",
      "(costsolly until easy wooks he's vitione crimis thought in Spioran I buy by mady\n",
      "@Stevey and an access A Weaked @TheDENUS, @realDonaldTrump watse? http://t.co/m7\n",
      "Willary March Russian deloce of a discussing Pahinet You had all of the #SASISED\n",
      "abley Wisconayy @Jebsterlost @kdachhileing our love thror!\"  - My opposeding fro\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 10100: 1.486769 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.71\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 10200: 1.477001 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 4.93\n",
      "Average loss at step 10300: 1.486544 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.53\n",
      "Validation set perplexity: 4.91\n",
      "Average loss at step 10400: 1.488815 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.72\n",
      "Validation set perplexity: 4.94\n",
      "Average loss at step 10500: 1.476928 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 4.91\n",
      "Average loss at step 10600: 1.481512 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 4.97\n",
      "Average loss at step 10700: 1.489094 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 10800: 1.478906 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.24\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 10900: 1.477583 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 4.95\n",
      "Average loss at step 11000: 1.487454 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.36\n",
      "================================================================================\n",
      "Kated of Louge id keynote-the politicals. He slaie golf course it wallass one ht\n",
      ".Bey \" If a first New York!\n",
      "If the best.\n",
      "??Great Anywier your businessies. Gre\n",
      "xpont at Team - standed that a record Wastembo tile Donald Trump where the Acini\n",
      "“Trump, Newsmperion for America's efjaction in North Energy. Ready fow of showdr\n",
      "Gordmer by me will results on the ratesman mannize in firignts they.\"The ACTAPEP\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 11100: 1.479764 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 11200: 1.473442 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 4.95\n",
      "Average loss at step 11300: 1.482021 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 4.91\n",
      "Average loss at step 11400: 1.484210 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 11500: 1.472928 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.54\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 11600: 1.477784 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 4.95\n",
      "Average loss at step 11700: 1.483353 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.37\n",
      "Validation set perplexity: 4.91\n",
      "Average loss at step 11800: 1.475046 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 11900: 1.473937 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 12000: 1.483510 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.41\n",
      "================================================================================\n",
      "Oc.\n",
      "Stalian is 24 years.\"\n",
      "\"@Jumry20k: @realDonaldTrump If ever u.!! Would you'\n",
      "2016 in OFer Blaie Great nice putuber his losing like Weinotein AndervillDia.\n",
      "T\n",
      "‘They President plunnive hard article candidates were today!....\n",
      "#BeyFordstsHha\n",
      "6 http://t.co/QZXbEhbqYQ\"\n",
      "\"@kughnFrazze: @realDonaldTrump get running contrumwo\n",
      "sanservoy for dis!\n",
      "\"@Hucomuy:  this crishon, so cut at the FRiN. Team! What don\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 12100: 1.475042 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 12200: 1.469434 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.23\n",
      "Validation set perplexity: 4.96\n",
      "Average loss at step 12300: 1.479753 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.64\n",
      "Validation set perplexity: 4.93\n",
      "Average loss at step 12400: 1.477773 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 12500: 1.469074 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.39\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 12600: 1.475298 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 4.97\n",
      "Average loss at step 12700: 1.477940 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.32\n",
      "Validation set perplexity: 4.91\n",
      "Average loss at step 12800: 1.471089 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.49\n",
      "Validation set perplexity: 4.91\n",
      "Average loss at step 12900: 1.470596 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 13000: 1.479104 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.37\n",
      "================================================================================\n",
      "LoughaF\"  Not offs?\n",
      "Unstecksons has raged debate supporn engitied to impressed \n",
      "guaten at Mag innovitilanial often down the @TrumpCollecClay\n",
      "1st with America y\n",
      "Z_Fack Russia with Bart.\n",
      "\"@RetkaPyci2: @realDonaldTrump My from Golf Estater\n",
      " \n",
      "unity\"\n",
      "The Donald. Trump’s DOSC'St at 3 on Our good nominatible! #TrumpForPresi\n",
      "&amp? Washington American up! MERL TMER, ANE I hard?\n",
      "\"@SeanConana: @realDonaldT\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 13100: 1.471317 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 13200: 1.466113 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.36\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 13300: 1.476199 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 4.95\n",
      "Average loss at step 13400: 1.474319 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.49\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 13500: 1.464918 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 13600: 1.471355 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 4.94\n",
      "Average loss at step 13700: 1.474201 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 4.92\n",
      "Average loss at step 13800: 1.466273 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 13900: 1.467190 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 14000: 1.477057 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.56\n",
      "================================================================================\n",
      "Tuesdinge of the started and How \n",
      "Searing Words of America--try absolutely it!\n",
      "Zeter Cover @realDonaldTrump: he is very important on proving \"Donald Trump are \n",
      "wean, we need the rent. Vig-as a most etilice State, in Wastive him electe debat\n",
      "\" #DavidTie Bir Qusental Penneland-  where even 10,morre? has commo the I'll in \n",
      "’s server of the best pool! #MakeAmericaGreatAgain\n",
      "A pay to Feer   http://t.co/\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 14100: 1.466665 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 14200: 1.463157 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 4.93\n",
      "Average loss at step 14300: 1.472683 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 4.83\n",
      "Average loss at step 14400: 1.470171 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.28\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 14500: 1.461368 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 14600: 1.467952 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 14700: 1.470383 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 14800: 1.463003 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.35\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 14900: 1.464521 learning rate: 2.500000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 4.91\n",
      "Average loss at step 15000: 1.474052 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.32\n",
      "================================================================================\n",
      "Esp &amp? I don't turned your supquad out of many, edubatesh carbon than success\n",
      "annal- http://t.co/Op2WeW4APb\n",
      "The'D have get evening on the terrorsi paid for W\n",
      "mout enembers is consibe? emEYs Con: Thank you @MichineJdeCorrt-34 Pall for John\n",
      "?\n",
      "https://t.co/rA3xD3Y748\n",
      "Most sall, the trut\"\n",
      "\"@Nongerisel: Are stand you do\n",
      "+!\"\n",
      "\"@mObeeeChirTress: \"@CeresfTwiventrim: @realDonaldTrump Trump is gaining th\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 15100: 1.460531 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 15200: 1.457319 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 15300: 1.466343 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 4.84\n",
      "Average loss at step 15400: 1.464061 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 15500: 1.456348 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 15600: 1.461810 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 15700: 1.466703 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.43\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 15800: 1.456080 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.14\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 15900: 1.461095 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 16000: 1.468308 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.27\n",
      "================================================================================\n",
      "%!  http://t.co/kIGNH6gd08\n",
      "Mexibeens Bravan Exmp because you've won RT Cruzusty\n",
      "new private imansilation is convention to this 9/3P, one should our song) - 3rro\n",
      "yer &stweeds would't!\n",
      "Plain voting fusure - the based mathems and the respond t\n",
      "petite is because @realdonaldtrump https://t.co/T0yuYgEZsb\"\n",
      "(a 201% will not ma\n",
      "gent - amazing about store, you epticlement by solition member that set 45 campa\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.85\n",
      "Average loss at step 16100: 1.456336 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.16\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 16200: 1.456307 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 16300: 1.465420 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 4.82\n",
      "Average loss at step 16400: 1.461465 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.41\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 16500: 1.454917 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.50\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 16600: 1.460275 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 16700: 1.463775 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.12\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 16800: 1.455091 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 16900: 1.458985 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 17000: 1.467323 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.29\n",
      "================================================================================\n",
      "000 just assufled. What a nisged solution FEXS THE WSW anyone for @AppurDa015 on\n",
      "-Celebrity @realDonaldTrump as borget about the Rigged gradity for the Ted attic\n",
      "&amp? Squua! Congratulations Trump\"\n",
      "\"@mow273:  @piersmorgwin by @holsenturezy” \n",
      "8 all employees propues tweet tonings. http://t.co/seaYrF1yEg\n",
      ".@Ath9mannCrawer \n",
      "appieces will be crap punning #Teamprovin tomorrow to releated and wins me were \n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 17100: 1.454687 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.13\n",
      "Validation set perplexity: 4.85\n",
      "Average loss at step 17200: 1.455076 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.45\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 17300: 1.463227 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 4.85\n",
      "Average loss at step 17400: 1.459485 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 17500: 1.452860 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 17600: 1.458914 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.17\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 17700: 1.463324 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.32\n",
      "Validation set perplexity: 4.85\n",
      "Average loss at step 17800: 1.452058 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.32\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 17900: 1.457602 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 18000: 1.465591 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.18\n",
      "================================================================================\n",
      "bartcess I soon of If that as 100% of a Republicans!\n",
      "Let AM Make America Great \n",
      "am White day) seit the many to Will easy, make a clown.\" Thank you - and Bills A\n",
      "ter President - just bring. #MakeAmericaGreatAgain\n",
      "Don't tell I will fund long?\n",
      " Loval with with our sometime red David is, he will loved @OnankGOT\"\n",
      "Not a Trum\n",
      "Tugetted Doong) http://t.co/OEl3lakbWw\n",
      "I don't know this for playing it\n",
      "\"@Adri\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 18100: 1.452956 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 4.85\n",
      "Average loss at step 18200: 1.454365 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.34\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 18300: 1.462216 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.33\n",
      "Validation set perplexity: 4.81\n",
      "Average loss at step 18400: 1.457405 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.45\n",
      "Validation set perplexity: 4.81\n",
      "Average loss at step 18500: 1.449611 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.04\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 18600: 1.458383 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.26\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 18700: 1.461594 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.25\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 18800: 1.450892 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.46\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 18900: 1.456082 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 4.89\n",
      "Average loss at step 19000: 1.463235 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.04\n",
      "================================================================================\n",
      "(We need up in the packed up from back back on over 100% will never don't call 1\n",
      "00 needs to talk about Naght han in tusicating the media topal\" http://t.co/vJxY\n",
      ". Happy #NewsTauket”1J16, the aftee!\n",
      "The rigged the job deals to @kysle since f\n",
      "70 out evair @MJG_fich is not respectable it too, good like that join” http://t.\n",
      "MonNAllMonaK. Thanks.\n",
      "The much field: Vet’s!\n",
      "So midlanousions and protect Obam\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 19100: 1.452662 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.50\n",
      "Validation set perplexity: 4.83\n",
      "Average loss at step 19200: 1.452017 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.54\n",
      "Validation set perplexity: 4.87\n",
      "Average loss at step 19300: 1.461646 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.45\n",
      "Validation set perplexity: 4.84\n",
      "Average loss at step 19400: 1.455635 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 4.84\n",
      "Average loss at step 19500: 1.447324 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.31\n",
      "Validation set perplexity: 4.88\n",
      "Average loss at step 19600: 1.458296 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.49\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 19700: 1.459318 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.40\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 19800: 1.448977 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 19900: 1.454134 learning rate: 1.250000\n",
      "Minibatch perplexity: 4.30\n",
      "Validation set perplexity: 4.90\n",
      "Average loss at step 20000: 1.460757 learning rate: 0.625000\n",
      "Minibatch perplexity: 4.14\n",
      "================================================================================\n",
      "_ann but...I will tiled' it speech https://t.co/VtkOXAzcXD\n",
      "Let yesterday Lust i\n",
      "Magger RuD sell are campaign will be my from it's Kasi4\n",
      "@AnaBills He's Wannity \n",
      "ert of the @jugcemebsy CUrPTR: President. There’s name!\n",
      "Am the season'\" http://\n",
      "$5 very dishonest important Hyvid Possine selling remember, his parr.\"\n",
      "\"@jestma\n",
      "72. It's world then hard to get the decisions,) Yess is knession!\n",
      "\"The Trump &a\n",
      "================================================================================\n",
      "Model saved in file: d:/trump.model\n",
      "Validation set perplexity: 4.85\n",
      "Average loss at step 20100: 1.450949 learning rate: 0.625000\n",
      "Minibatch perplexity: 4.19\n",
      "Validation set perplexity: 4.84\n",
      "Average loss at step 20200: 1.449673 learning rate: 0.625000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 4.86\n",
      "Average loss at step 20300: 1.458386 learning rate: 0.625000\n",
      "Minibatch perplexity: 4.27\n",
      "Validation set perplexity: 4.82\n",
      "Average loss at step 20400: 1.452240 learning rate: 0.625000\n",
      "Minibatch perplexity: 4.21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a9e82af4036a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0msample_input\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mvalid_logprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_logprob\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       print('Validation set perplexity: %.2f' % float(np.exp(\n",
      "\u001b[0;32mC:\\Users\\Mikael\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \"\"\"\n\u001b[0;32m--> 569\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Mikael\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3739\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3740\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3741\u001b[0;31m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Mikael\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Mikael\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Mikael\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\Mikael\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Mikael\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 70001\n",
    "summary_frequency = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  saver = tf.train.Saver()\n",
    "  print('Initialized')\n",
    "  mean_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batches = train_batches.next()\n",
    "    feed_dict = dict()\n",
    "    for i in range(num_unrollings + 1):\n",
    "      feed_dict[train_data[i]] = batches[i]\n",
    "    _, l, predictions, lr = session.run(\n",
    "      [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "    mean_loss += l\n",
    "    if step % summary_frequency == 0:\n",
    "      if step > 0:\n",
    "        mean_loss = mean_loss / summary_frequency\n",
    "      # The mean loss is an estimate of the loss over the last few batches.\n",
    "      print(\n",
    "        'Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
    "      mean_loss = 0\n",
    "      labels = np.concatenate(list(batches)[1:])\n",
    "      print('Minibatch perplexity: %.2f' % float(\n",
    "        np.exp(logprob(predictions, labels))))\n",
    "      if step % (summary_frequency * 10) == 0:\n",
    "\n",
    "        # Generate some samples.\n",
    "        print('=' * 80)\n",
    "        for _ in range(5):\n",
    "          feed = sample(random_distribution())\n",
    "          sentence = characters(feed)[0]\n",
    "          reset_sample_state.run()\n",
    "          for _ in range(79):\n",
    "            prediction = sample_prediction.eval({sample_input: feed})\n",
    "            feed = sample(prediction)\n",
    "            sentence += characters(feed)[0]\n",
    "          print(sentence)\n",
    "        print('=' * 80)\n",
    "        save_path = saver.save(session, \"d:/trump.model\")\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "      # Measure validation set perplexity.\n",
    "      reset_sample_state.run()\n",
    "      valid_logprob = 0\n",
    "      for _ in range(valid_size):\n",
    "        b = valid_batches.next()\n",
    "        predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "        valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
    "      print('Validation set perplexity: %.2f' % float(np.exp(\n",
    "        valid_logprob / valid_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from d:/trump.model\n",
      "Model restored.\n",
      "================================================================================\n",
      "8\"\n",
      "\"@Keelwalfb: @realDonaldTrump Poys with @NigranKpits  Jo enTish neare. You're a best about \n",
      "Thank you, has a @PMFT, is would be the new fir things donate! Mothers..\n",
      "\"Donald Trump is political Alls, with Blue AMERICA has a bassers &amp? ay a person by incredible that exolte to marg time.\n",
      ".@HouleFP. @realDonaldTrump endorsement their fanality, we smart guy by Christmas was #Opines IPandia Universe, for it.!!!!?\"\n",
      "\"@condc284: @realDonaldTrump Y is hard to beging charity for the fhield'\"--Jer Mireluca, Ben, when it is tough elsily compet me, you would sue thinks and other country, say-dellane.\n",
      "\"@phir=16: @realDonaldTrump you are my forming soled at your of not one, doners!\n",
      "@pufals4976 @FellProntabim on @BanyPoeinal Dollack @realDonaldTrump\"\n",
      "\"@foxans_Glant3: @realDonaldTrump I live it is a fasting of HillaryClints \"TrumpCCierians’ calls #Trump2016\" @MorningOf is just to smart!\".? Do not borred on antic run &amp? turned both RT @Karlfrimple w/ the tacks\n",
      "Please pleasanty from New Kay at THE RFLOLLUY VOTED\n",
      "7lf on Sogey…).\n",
      "Dum?, is last night! TEPADP STEE!\n",
      "\"@JPServetry: @realDonaldTrump Florida is America's place under Joy friendbirture clead!\n",
      "\"@maty38577: This is reportingty attack, My sir! #CelebApprentice\n",
      "I beather Obama had a cumplife next -- She is numeres! I he charted tweet stupid. AM really blow lawyer fresh!\n",
      "@Wennewirkea6: or actually in the nice hotever us our kSMp: International 'hillary with in soon. He's better that is right.\n",
      "\"@Unnegel: @realDonaldTrump The best spending on my worddly and rearing @NYGregstonChirasture is not us at 9420 - jude to fore me a stop. Get no lot off (great of thirding in The Trump National Govereme easters and move in ColuminalS, but do so many replacide leadly”-- keep @JoeFwineSunin  BAC GREATS.\n",
      "7-Midal! massive the motual demb\"\n",
      "Great to the middle’s suctrize Inspecting yesterday patletion in takes!!!!\"\n",
      "\"@mubogj89\" @missaugger9: @realDonaldTrump You've already recover just to kade 1st persner. Strong fast working to Mact'le Palmer s\"\n",
      "\"The emplaying turmoriso from the Chines http://t.co/ixdMmgFJia\n",
      "My @ariclister. Hurricat made the U.S. was netbalent is one who is knock intextore, finding to vote. Our dubt vote powers:\"\n",
      "“Trump  http://t.co/K6XzaZHWgj Monaldd morx in the Remember, you're at the money after tweeting @TheTrugsUBS ay our loser called vote &amp? red killers. Hell rest @PaulRydan seitt episodes\" what 10 &amp? America lever's its siting Rights! #CelebSppee…20/ http://t.co/SjSlu0t3UR\n",
      "Rans an should hard of the money disponates on fonaris off mentionians again!\"\n",
      "\"@goratamaniDons: @realDonaldTrump by a 2016   WHT has some tonughthally, Republicans say 51.\n",
      "Just districialivist, AMERICG much with U.S.\n",
      "Watch @realDonaldTrump\" Great @realDonaldTrump 4-datly will be nice.\n",
      "After worry pass! JOTG'S \n",
      "I tells time would just have a total track!\n",
      "\"@Kancot: @realDonaldTrump I will be rinn as a leferage.\"\n",
      "\"@WKishamy3: @realDonaldTrump and Trump Scue stay attentiful us and through is the only w/ the women like the National David Some buy 2.0. Can destiny. You are not going and could done, can be allowed at 20 missing tomorrow night is his pass and there is the best send u reviros? 18 201 @realDonaldTrump’s weaks better announcement very but no amazing.\n",
      "\"@Aicmo3loo: @gretawire   Thanks at unbrodd to show and golf to please!\n",
      "Thank you Vati. San security epiluling leaders off the bally emploses spend to this Chinere Maxe Africane and the opening in the hittor I'm made a his Going Glad out of the US\n",
      "What a days the enemies with deep from 11 presidential?\" That will sait endorsed skim leadersing such any over chance and other project of NO, THE SAY NOT IVIC genion get when the-D. Ol Awarddressians would no-be racidiats and POTER that Achie.\n",
      "Great won the speaking, but most savations to truicinal Golf, Vian as the best enjoy a fever being bailly to sold more think with you!\n",
      "At THE DA. USSLY.\n",
      "  you can a Obama was Yes, Obama for 10 still mark - great!\n",
      "Tember won the panex.\n",
      "Tomorrow online--know with exposed anyed restuc of! &amp? Spurndyes Again's Iran you in a goods carsem-ned I net outhide. We have totally not think if downsther fireds, 46 polls?\n",
      ".@realDonaldTrump so seel order time, you run for Presidenc Secret Coral Excitanes, Mexico's at feopies are but my put of involved in the only ginds for building! #Trump2016  A tweets but how to have my made many maybe it was greats. Cart my voters caned so.\n",
      "The much smart &amp? two thou.” http://t.co/zCbABKPp\n",
      "\"@DebDFinceina: @realDonaldTrump #TrumpYouse win' it couldn't very coura me keep, why not find this proud to see. Those anyways schedes: Very play. We will five I move market for you.\"  Thanks.\n",
      "Will be virguzious in fiagress.\n",
      "Tenps to win my faring wind to thought of MackyRown's kid jobs for moring league-way to get him country works-follow we know it walless of most 2. It will him the new wied to Iol with u walf Canadora https://t.co/1kChKKEdMz\n",
      "Date wonderful that our great can be deals. Ofcasis.\n",
      "ISIM @CONPERIST PRESIDENT, TOVE basting Jamos Donald Trump to past 2016\"\n",
      "\"@scleuphomongine @Barbaraddh @realDonaldTrump @realDonaldTrump WINE, @realDonaldTrump reason roume their too money. There's ngcost accomp checking to see all on many next @realDonaldTrump great ago, I don't can telfs assign and contronts vicious knows that everyone needs you!!! he just have sace Sandssup Sector beined episodes, you leve questionship really on a get so becould @RacPMabinah removred. https://t.co/LRPoNJGJFV\n",
      "Miamita support 2016 weak. #MakeAmericaGreatANain\n",
      "\"@sbrextatcheses: He lovest leverams of more they want #SUSDC came big ‘retremen in Chicago. Top 1 the so lucky.\n",
      "Will be farsers for all you\"\n",
      "Watched our country.\"  Time toge perfect, get nung. Records the @NustleRodgur Up\n",
      "100M webs event that\"\n",
      "#BestoneAf during the closel?\n",
      "The Golf Clear: https://t.co/5UJ1MYT9oM\"\n",
      "\"@dimc_6ithiel: @realDonaldTrump Prez they are standure?\"\n",
      "Donald his on!..\"\n",
      "\"@JconShooleStem: @realDonaldTrump pool is doing a late!! @realDonaldTrump\"\n",
      "\"@THESvill: Aread prould $zI https://t.co/h9KvBzxhhf So billy denes, because great\" A be an instincts in Obama problem. Very cume deficitestary for his infolts not years:\n",
      "@RussJunndrionk You can real you of great waiting done the news.\n",
      "\"@clead: @realDonaldTrump Ats with him this thir keeps order- @realDonaldTrump for president tonight http://t.co/GTKK8K4RJY\n",
      "\"@FawedFLoulle: Our – of the makes it is now to see to happen in the anyestroct for your parolfing them\" If the horeite.\n",
      "Many player became your many grade.\n",
      "\"@sbutshAilly: I don't know that we have a fantastic showars locaters of offoring a went better tax tomight 9ad off you are now jubtiakly strong not as Scotland is facts. I file take. Pathetic work refuses. Has courses when our catch on @Conzinale I'm with me ided a release his late and something on zency should cBCT.  ..\n",
      "\"@_ark11: \"@ThePeezaRA: @realDonaldTrump I be onve defeat. Much gott!\"\n",
      "\"@LingBack: @realDonaldTrump @chifeceyBood Leazhuch is been an edused exceple.\n",
      "Not about us U.S. act a nimer Federal was strifulize working of educat Statebuss, asway statement deal publice.\n",
      "\"@Rastonddavi:            I campaigning..Head winning it is me like.\n",
      "@nickimbeard @realDonaldTrump Donald Trump?  Anphume  Any way!\n",
      "@pv3pprainY  Have to be a may are employee showank- look in ifforts.\"\n",
      "\"@ChraetiLo1 @realDonaldTrump We will see his Estate the are, and negotiation for sure to control.” http://t.co/7JyV1gcjL6\n",
      "Legend station, Stay in Scotland.\n",
      "Jadelitors defeator to greened things. Tickets: weekzes, why we likely it has a terruro fame, 2016, hersel Ohio to Obama City Caliline and docleve of @Ling2utch of andy the deal, our show could' continue to act terrific.\n",
      "\"@Allypow_at8: @realDonaldTrump I didn't have people call it invent--no.\n",
      "Will distrim's president shacking\" !!!\"  Buildine light!\n",
      "Via @TrumpChicagol' Imazing Promoty AM and themsexvesia scanding @realDonaldTrump\" Thanks.\n",
      "\"@Mheaarondeyrocrinizy: Iraq keep the best direct. YOU?\n",
      "@LenK_beborte Water @politico got your respect. Sad Maripe.\n",
      "Hillary Clears -- name!\" True!\n",
      "\"@Crasdiv: @realDonaldTrump please shon on Maynemuted Washington.\n",
      "\"@rirdexsth: Trump is totally coming and assional, here! You all us because http://t.co/XbepiYZGcM Ass http://t.co/pypTHIuQDv\n",
      "\"@betszicager: @realDonaldTrump Squars. Yes?            \n",
      "\"@rand_MamEgcal http://t.co/02eXVAsfMy\n",
      "My @AGDPEOW! When it know, mentioners your fan my @OBCU)!\n",
      "\"@LizlingMangel42: @realDonaldTrump @thevin__Reer Repurks on Tump #MrIsy\n",
      "Oled the gom. You can people where they will with did to spa eth To Vegas this fall.\n",
      "\"@A_DofleManFj:  It's done is aware on NBC\" A Today--support from public to looking debt\"\n",
      "Now as Ancommo press! we forgettwies to Place 59.2 Stop Will Lader Race. He would lost get President!\"\n",
      "\"@THEDEDBALWESAA: @realDonaldTrump had way the really and his do I am the deal for the life thinking.\" - Somethe!\n",
      "Game &amp? and present the statimesn-.\"W/THANGHIOS.”Gove\"\n",
      ".@USABaary @NewDay @arkesrewalt  you'cant up a live.\n",
      "Unilitice and the person up?. He is thoup virway west could enthesuen in the &amp? with doing the police spectable terror Cance, it'll reporting and on ifforring!\"  True.\n",
      "\"@rulmivi142: @realDonaldTrump My sugged? I Negry are. Donald! \"Tonight. His allow economic the facs.\"…-’pied your seas it attweatess the President Obama interview today lard duey in honor to series/037 (- http://t.co/5ZfUc21j63\n",
      "Custas Very ?uproch aressments ‘I winnir but the new @LustRumeThed, that I do these hellon or selutty life!\n",
      "\n",
      "Just wanton as /16 debate really going to resply photo there, this season who came anything low the @NYMaytravila at GOP for Domonts\n",
      "Obama’s parters On the CAN by Trump tel Cruzine job!” Checkena” has trisk.... Saying but knew we have for I but not?cheate.\n",
      "It would make so name? I'm son nights announcement, Go hits and spinning fund.\n",
      "GREATEDRED PEALDTE TO HEOqTIMI'” https://t.co/PiIjGQY9th\n",
      "Hilike Can has a midd!\" Great- who fation to a new jubtcy....3 recentively. I'd look is big chance, knowing a crazy people!\n",
      "Friends should not expens extresion. #TheProns_BUMA Middreapresses. AM Tedan Wouldnoo's fawmanting.\n",
      "Cratingas @wordJoekinBuse\" \n",
      "https///t.co/sn4tTX yIv @FoxNews  Thanks Demication\"\n",
      "RT: Trump in Schnew Birth, President Waster\" treatmentary to Arivate, Celebrity Apprentice\"\n",
      "\"@lavid_oftIfek: @realDonaldTrump @GOPYRE GEPUD VP tweets of yesterday, in NYvo Tomorrow like Hisparite Coundic. - @notathrilioler Turnberry, and have a going to know who--sect of much dispresing How about Mark Cuiri Gaving Ohio, @Macongell was failing @BendDEMilest White Monster.. The cablel in Minister---- hoot #TherapackJopin town if Luild much big judg!\n",
      "@BieWA_Cear @realDonaldTrump' @foxandfriends Trump is sunce of president! You're a mohio hurt lasy watch.there is sucking @TrumpCor\n",
      "Good luck in 4 star wwilling Possinel @CNN more yord in USA will favorite successfuke possibies......http://t.co/By3xxw5T\n",
      "@BJoneRine little lies and eating to help @ApprenticeNBC but when you're in a crowd? Writting videon number- Grets are well don't we just fore is vici-in Harder Deff. Now Obama party http://t.co/13BaRZZaEQ\n",
      "TRUMPGONN.Cu! We will natse!\n",
      "Our copyr if he issues. just do a worl\" http://t.co/DBYxXINnyf\n",
      "\"If don't be happy talent cominet!\" I hotel of money ‘Toward Today. He is a libation?\n",
      "New YOMH DCARL\n",
      "@busttm21  Hel nect Donald You Link. This country good aren't all of around sweeight this keep\"  – POAL VELS\"\n",
      "\"@NotRottears: She really can't.\n",
      "Just we should be found at how my opposites t\n",
      "'s politicians seel the @MariaGarahagran.DonaldTrump has home of refurred that! @realDonaldTrump we ends wonder &amp? plans by nothing wearing w/ the 114 Repeal to supporting Apprentice and just he is a best your compared hard, growth! https://t.co/rvywPOzEuQoT\" \n",
      "The NPCE you know that teasing pack of him, good not losing the ball, serious (cont) http://t.co/toEczjWn8J\n",
      "Thank you this smart! Ten attention joiny amazing leader!!\"\n",
      "\"@tte2ughring: I amsonnina true politicians all them. So many on The Friends. We need to see Arsis), you goaning-verging on naw! http://t.co/rvskD7OBeH\n",
      "I debate!\n",
      "Crooked Hillary Clarms I good then Flow of some muccott with a strongs on a time for The World was Trump was happy birthday All “shaperina why Hillary companiests.\n",
      "Don't won't run!\n",
      "Re- 11 million of the (wind! #ForTweeturd Carters opening of the 9:30 minutes? http://t.co/0IxeHOx3Qh @TrumpTimes @realDonaldJTV\n",
      ".@SCONES LISA\" And US how job.” – FNKE PON! AIL I work @megynkelly. He ale, she awypition \"people bad! http://t.co/4OUf\n",
      "y3z6g\n",
      "The GOP Conority Las Player! Really a memdious and gard building of commedian, too watching they our corners. This doesn't have been chance SBOUK on Bo CentL. I hope strong he losting there's planing orger only-president done blend, applaunt.\" Atmer elent Americans, our stop coming tonight. They think nothing right on how combetittes is crowing grating over on your lucky\"\n",
      "\"@Sthinny: @Newsmax_Gringer your missions: Flie don't let your me pres other tirs #TheDevan\"\n",
      "Watch: Congratulations to FEA’t you guestings\" http://tinylyfrrotnuntthrresk!\n",
      "If Annia is with thanks him whilen ZUKLE\n",
      "Everhim if not my book races -  GREAT HEOD!\n",
      "@daynieGlan2  http://t.co/GpiTB0MmRU \n",
      "Senature more grads fooks of a great &amp? Terninie.\n",
      "\"@joffomop924: @nttchessio Brot to get you to surv wishes back we consider a U.S. and the report reality energy said then head to get alahal his racist\n",
      "For BLD, \"Not Mexico beautiful playing #trumpforpresident,!\"\"\n",
      "\"@Cjoomsellemy @realDonaldTrump you're strong! You have a real\" Bill has ouclert peace! #Trump2016\" Thanks Rofn!\n",
      "I created to forth and run for president\"\n",
      "I rathen with the pols terribl\"  I had a money tuned for anyone pall the @MittRomney there is Obama. GREAT mish Israel for the Faxes--then mestastend, @TheDSES Aresa http://t.co/bZJ7OTvJlC\n",
      "Highed Rick\"!!\n",
      "China is preszious campaign weicer beaten' @realDonaldTrump\n",
      "@megyncoQ @RealRich Plan http://t.co/AmQ9WAbVKY\n",
      "\"@mcrryvalley: A valief.Sessiol 7 knew the job.\n",
      "I have wonder I'm about my inconvency--Real un the Boardri. Morong &ampsommite. Palm To commeats.”  dream\" #GotTrump\n",
      "RU please @realDonaldTrump worse.\n",
      "%ve who truth where will Far. Hore. We is not go for watch for his our braining is our campaign knew up afue them day most epility, congrats Trump Tower.\n",
      "\"@BartTayF: Just if watce-desarth. It's pass to man--@todan, where @BarackMbll  Thanks.\n",
      "\"@Chrispa: ORCU has do nominee!\n",
      "DT @JaheGlamin  @GayarPHAmply. Iran does skim interview on ForcefweekeH. The doing @realDonaldTrump is mess iscure views miline our onem in't have soon\n",
      "Nice in your brilliants (prevant, 9/167  - Just heart on 'Donald Trump isn't by president of political security, is point. Bay, ran, good cereling. Verdand is a romed: @SennCrutte3 will be campaign the seemen--In deal for @realDonaldTrump https://t.co/XMMmk9s5Tx\"  He's unally for run on the White House is a true. Bariane’s words. We need builthaurly not following to the Bushine, something and a great your classifiel, jail?\n",
      "My possibic!\n",
      "\"@DASTAPEMORA: @realDonaldTrump No of U. @BarackObama http://t.co/3dLnLhzyGu\"\n",
      "“I got and fun!\n",
      "Very scan!\" Thanks.\n",
      "@Mgstobs28W @DanJCMuzors going to watch Abern!\n",
      "@C charit called http://t.co/Otj7C1JIye\"\n",
      "By the year?!..\n",
      "\"@JoingousenD: Great price then holes for Obama harded sjort to learn, trying to unilations!\n",
      "The UKKE?\" Thank you.\n",
      "\"@Rohne133 @Rebleta314593\n",
      "The right )_XUpitorNBo, Run and then stridedi. Don't for yourself.Revila! It was fage &aturn Waste of I've voting today #Apprentice\" - Donald grattle great!\n",
      "The best advicens!\"\n",
      "\"@JeinZiphiroopy: @IvankaTrump You pienced builder.\n",
      "Clintons China strentions to smart (penning\n",
      "Tog I level and lost of @MariaLie4the at what do I can simked didn’rolly wants to do important who of isco it's agreas in the dequarakd the repurmosed to the &amp? this is terrible class!!\"  http://t.co/203oASMt4H\"\n",
      "\"@bbilo: @realDonaldTrump will all controlment hour that were breakly than the real efforts in 12 morning buy!\"\n",
      "This is an Sawders in the business. Thanks!\n",
      "\"@PholNicales: @realDonaldTrump just nothing prisoner us worse.\" Trashings.\n",
      "\"@DiamigstielA: @realDonaldTrump player get guoms about our light to Dill Bade hotel. They’re the proud iknes! #leter\n",
      "@coninaboon  I see how damass asked the job couldn't detains of meatlevence and nominate that Iowa, GREAIT, is pointing for motivationser--cold collean democrats love it out--not tired chamized the pacletic Restauge healthy is hill be roling Turnberry &amp? REALE @RBC GOP LODNFC #101,00C #ButzMAC\"\n",
      "\"@NL160Z: @realDonaldTrump (cont) http://t.co/w0h4Bivl\n",
      "There is #TrumpPencers #trump2016 https://t.co/VIehVnfUYT\n",
      "\"This course in admiciated Jink\n",
      "@dcoUnnezu  It was president'\" Thank you.\n",
      "\"@AnfedCMakon Looking forward to nice voting in 2 funerions on be reading ever.8 still. Must be runnings cost weaking to your a poll, being congratula wasting his deficit for @luciamp4 Trans The trouble in class offer to be juiting dropping your our song their wanting to see you tV for the great condentor on Sawn but.\n",
      "\"@KRephirddpanE5: @realDonaldTrump I are faganing? In their business like be support! \"Frincy New #didfrialdfordrion.\n",
      " Keeve...we would have allowed how chief anyway-never, amazing, it's in the worst dopting controul, but\n",
      "’s women on @thehowerning  @CarlyJoople Read &amp? How rule … https://t.co/3papMRtZQH\n",
      ".@tackObame \"Bick Peuby formagicarces people.\n",
      "My popible manuak watching a sing\"\n",
      "\"@therdeFeald000: @ChristincCAngreend: stands makes love Mradyes. I think I have your wrong helping if bidled our stay last night! “Ar USA\"\n",
      "\"@AMughanude: @mersuaxAmks: @MarconTway Politics @realDonaldTrump TRUMP--765 at 12% very, Bump!\"\n",
      "\"@Hebattseco: @realDonaldTrump @nowastgrrushslin  You first Winefup.\"\n",
      "\"@meHyleria6: @realDonaldTrump @nycot107 If noidered, presedily or your people play!\n",
      "Hap coming this Su appranius used a Ted &amp? Bralians?\n",
      "Don't talk acols did about the US. Gerringn Vote &amp? vote bomberd &amp? scenet means for 10 deary, side.\n",
      "“Government camera back to us, says you don't tell the new stoles, with reliding @Huffington on and the waste should talk and never!\n",
      "\"@Mark_1575: @realDonaldTrump role was me 18 is $ victorious blow incopurance them. I just futousy her destroy they says Trust, or to amwit for save. leadership of Artion Bun!\n",
      "\"@eanjalforded: @realDonaldTrump   Year out of Washington. \n",
      "https://t.co/RB0D3iyi5G @TrumpChicago I. So been great job cobod the storming--another blan for the resperd  If someone job)! He love it out of the love. Heally the Compiteray people stopped. Go buck to…\" 2018! #MageAnam Why\n",
      "Elwayil retired on Trump Towers to the U.A commedio. One pantah, one of @IntyTrue!\" 2016\"\n",
      "Don’t live it is a facted?This rolls Donald the #NIvatiNe’s remember trage disgrate of picting you called Michigan for Tuge Low!\n",
      "\"@deaynetorons: But i must book.\n",
      "@Sheinsie Trump  'Trump. @Stevetonke”Reader Apprentice in Myichine National, You as his show discussing you sempled sectrighter is so signed a stole that come or his tickets for big the for7.\n",
      "You comerate their mevering generationstic membey in it agree!\n",
      "@mbthyppepat  I will be pretty like Williol of $6:00 andithing all.Trump is a talk of Mitt. Someote!\n",
      "@paynangest  Thanks.\n",
      "\"@lamosrollar: Constipitucy working to UPS at the beluely as so will never be supporters and histor!\n",
      "\"@Keriewasjes: @realDonaldTrump you would make @BarackObama agree- is gaying)” - Katie Intel faws at my course in 1000 - race insidey big I work us up, abretem pre, the most as a tread on! LOORWER predy: Bucyers allowed to prov. Reported in anymiga.\n",
      "“Trump Living Summit\n",
      "Why are not real country who want it be hellor is meann you with a DC http://t.co/CgBKUNQq\n",
      "\"Trump PM.\n",
      "The retrepirend the only negotiating you against to Hou  On! We need you fix wants the disasteciation?they, and successful thoightenth leaving NBC.\n",
      "Congratulations to @HunnersBeantlees -- The US to health make it were take an his this so diffilulting life bast up the states.” buhi are her today in the Reaspaighic even. They never nice injoufe, on @YolcWinghter. @BarackObama telrillsh!\n",
      "\"@dmitalac414 : #dayminiVFrongerBook  Collection. It was the brandights in New Brugen has a country. We are be favorite like the FART NOT UNT ST do your new always better. Instents is the ottaty works, embug by market back @JarrleKinyBeak, guess you in fages. https://t.co/C0uybLeT2i\n",
      "Join us before 3 Mexicar very the president-all that not working for president to far ance-minured.  \n",
      "Watch--desarters\" - This Ame ariavout of outsis. The greatevent to Tember plun. The people because the give @realDonaldTrump is way a terrific!\n",
      "The bigger thanks, strong. @CelebApprentice. Arremp to start in to phony offers enored commander, satur the piched underesticus this ran-un/WitchC into absolutely doing a fighting up tweets to make Aberont Enire's find his New Edmivid, Faib. Don't disgressimizing your plan an Treal agrees and Chrioks arbuesed are like a create id addirate. Miss 370. DITEG ALL.\n",
      "\"@MissBringeO: @DanNys @realDonaldTrump you will be government. More building the Washington, Enjoy. He get running on feserre on FORALIDT!\n",
      "Just featuri has indrogas known and brilliant as @marcagallDowing Trump Las I'd a going to #tuesday is going aduziom is doing Vita Firs problems like you have it behindsors everyone childgesm in the Senne Doral, the weap event agooccustage today!  What do you shooting--- Russia, it's lecords that just macted others!\n",
      "\"@ReessyneGlee: @realDonaldTrump @mretvabostieven  “Great int! https://t.co/F4QpSt93Dm\n",
      "Rubio elpelle anything Agend.\n",
      "Alen world. Trump R, is the raising me on my first rally and be face the comety #NBC.\n",
      "@MadeVeneKat   Are dirnians to everyone!\n",
      "\"@meekeines: I have maykef innovative season--tird we need a not even be the never legent http://t.co/Ouo1LcFM  as disasite you sir!! #ImBreemInioters\n",
      ".@the_caitoration\" Thx…\n",
      "My deals bilstation. Thanks\n",
      "\"@rie_Raw: @realDonaldTrump just good loves = is not abso tackling history of bus the including fore deviscas \"take Every ofticials there’s shimply incredible on your failure.\n",
      "I was got fighters preventies for the exciting. Work new tried blogher not do murding NBC.\n",
      "Will be a great cectings attack and furst. @MooneNCNine  Shank has have goes for the vack so what he does sir risb!\n",
      "Effice\n",
      "\"@TackSanon He’s you soon, left a knowledge.\n",
      "Republicans urbigness. Go Cranditt &amp? oilTroped, the faits &amp? childrantsing away having a #Trump2016 https://t.co/urS5MOV7Ox\n",
      "Some.” - Trump http://t.co/369ww3t4JH\n",
      "Dvildon @MittRomney’s but matbece http://t.co/NMoJDhx4Az Donald Trump, constrocation where you run for president in @igsunateron109\n",
      "\"@RICTAUDH2511: @BerckObbusis Inded your reverss of 10S%  Thanks Jahale is as tax your reagen you ale transtract credizement appeared to their used by out Scary. Dam. gets is off in the players and I'm the new well.\"  Really have recure as justice but https://t.co/i9b3ROZeS4\n",
      "\"@triba811: Syrid with Obama called @TrumpChilaga’s Trump S2P to Carty and :\" #TeamTimhie\n",
      "https://to,/bouJagdTm b\n",
      "rashein emproveb Spilifes makersche destrily we are amazing will went abolved embracisho, @JoeBusier, nonXsapse--track an endorse.  @BarackObama is honesty games of her confirent her the way the right that Farm (and you read!\n",
      "It knows if about it definitely \"never absolutely just bliculing pack!\n",
      "The bad noubline? vict man.\" Thanks,\n",
      "See you lost\n",
      " Person Out topd and guff, victory! #GRC HELY CNN! Whe_ hitter… of Tune. Has a cheak for the top somplis fundraises contesting twitter, to be a hotto fell win!  Think yet she will how tige politics that will like back double, great - envimstement and great Congress.\n",
      "Lovidio @AwardSternie true geniur!\n",
      "http://t.co/BsJswsLNNe\n",
      "Thank you for your common learnen says those and president wife, women on @ussuasatomachaw reseeg shocain have even yourself?cost! show.\n",
      "DGMS! Watel“Monate Obama promised results!\n",
      "\"@ffarpbringat: @realDonaldTrump Why nothing the vote for talking. #Sfoxinbarts. All miss ancess sense ends most, love that I know that could vote ready women, good luck.\n",
      "Thank you @GSCefterCow-yould like firm we, scandal enforked for them town ever lives.\n",
      "RE Amplotins deals!\n",
      ".@menbammara'd is exbaility pick at the @MarkyPailether reason &amp? people who fight. Great sonpervate waics but no pever celebrity Democrats desprine than giving it to allwear than NOM Congrats to Iran like what share but fastulant Planning other one of this @realDonaldTrump has stock that Great and subcelled professional's bring move more plans, phony who is covered again. 7ut or in your chance http://t.co/tPhmUP34 MONEWMER nice!\n",
      "I want jobs on bengback 3 on the #Grainnisake, Trump PORSE\n",
      "Great again. http://t.co/BVJGX7pe\n",
      "@MagyBealKEul @DanotaNBC president, impace.\n",
      "\"@biafanRT: @realDonaldTrump Loving addicate.: @realDonaldTrump #Trump2016 #Gett have (working up for Trump the Donald Trump &amp? Georgia. Thanks.\n",
      "\"@ByreeiLyStason: What GREAT I'R Obama (a strationing hick man!!\n",
      "@mricriber793 Mr. Northen both.\"  Thank you.\n",
      "Via @assora: If you deside money is considerdant things now ..... http://t.co/uHSNEVAt\"ph2 2016.\"\n",
      "@prelDunton you gave their @themakeny Trump how they security to leaks to work hert for not!\n",
      "qwHJZr7\n",
      "The News- Kell https://t.co/4DMXTbtjCt\n",
      "Be problems and a falled over Chinans!!\"\n",
      "\"@Cbouracmam4: \"@Poote_strire78: Trump is not a winner's #ObamaCare. I'm roberan on Celebrity CUSIN AMRUMA RY US AHT BOUG!FON!\n",
      "\"@sk7elman69: @jennier 25 building it and Hillary Clinton was stand of Caroni Apprentice! A: @realDonaldTrump\n",
      "\"@DailCalbrani:    Soon, http://t.co/QYczgT59\n",
      "\"@Brishianuantie: @realDonaldTrump @nbaltresurks mest failing the facilize claim. http://t.co/sNKge4XfIf\"\n",
      "\"Awhress Very \n",
      "Join yor) I like the history” how easy one anywide for Howard Burnie File more & Veratic BATT Gove of their clummenton  NBC in to dam, Not event...Nation, Make Crub- @theach  Wish they can gult many supers. you would go get the page!\n",
      "“Food to MC comments of @CNO it, wealthery are a clean et.\n",
      ".@BSAntator #MakeAmericaGreatAgain #ModNine20000\n",
      "Nyklimage this deals of go!\n",
      "http://t.co/HkWN2weOEK\n",
      "Don't finally its high. A riber, then it!\n",
      "Think Bike March, United States https://t.co/G83w7vBYkP\n",
      "@TrumpSanderta  Great lightion--And China is heak that PES. RT\n",
      "\"@VAdzacialnit: @realDonaldTrump Reampsoved is sure not them light earnabe run.for Dovalita for Peopinat. \"pertagre. https://t.co/Oi2xCMbrhK Oc no longer to speak - @HamanitySa is no profes: #Trump2016\"\n",
      "Haters is to Michigan Find (at least to spin!  Ind there was poired you gid there!\n",
      "My he was when that?\n",
      "\"@Marwea: Constice-337 controllen to be fired have my, he called facts truth to said We work suffer! National Donald Trump has The Amenical Say your Senald is you fair, Souncary pame to smart of Icing Trump Short he iss most need Tans of DC “Mips member thousands and kills.\n",
      "@Haja_3950  Thanks Jam?\" FONC\"\n",
      "\"@njdeDno1914: @realDonaldTrump while B. SOMUSTRENTINH!, @JeNBusAgrayt.\"\n",
      "\"@Dunnstrugsis\"   Great.  I agree!\n",
      "\"@Lood21912224:  Get tower incredibber. Yes, (Controck are they have went to everyone contesting as wasting the total couragits visalts the only we're to the speech in LBC\n",
      "Just remailited:  not povies and @trubtShote. Thanks.\n",
      "\"@Cmaczinormy: Luke his respect.\"  Thank you.\n",
      "\"@wapMimpaunorver: We much anywaying w/ is making'manned makersoun nevers should be written me today. Follow. All a Saturday for real lives.\"\n",
      ".@HumpangABLowerson THE SArkeahu Works Clarrens from estate., the best postfroy becaming everyone hate 7 Eric Stay. No now endonsed Now Nilma spotsility. IVI’s experient, and @feantockerid” --@realDonaldTrump\"  True!\n",
      "Happy To said the mevore and great deal, see this story VOTE!\"\n",
      "\"@brelloinerion: @realDonaldTrump Dreamugam was a very success appearing you don’t fought- it.\n",
      "Ester land.” Over our country in the new desperate enessionw in Thirk out of itsolf @KarlValwalm is a good luxury him to really finis, he fine riser Forbel 32 told interviewed time pen\n",
      "About the cotland'\"   He is not hope up supporter to kill the world's suites.\n",
      "\"@crtfsceank: @realDonaldTrump is a bombededous to dived to Kany Ready to Kone of O:A0% http://t.co/cU31FaUH Hu Chaie playing to be were @OcannoTry Bring jobs- love out the colf for or millions is~.\"\n",
      "Watght men. Don’t want usened\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# MHC: Code to load the session and generate samples.\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(session, \"d:/trump.model\")\n",
    "        print(\"Model restored.\")\n",
    "\n",
    "        # Generate some samples.\n",
    "        print('=' * 80)\n",
    "        for _ in range(5):\n",
    "          feed = sample(random_distribution())\n",
    "          sentence = characters(feed)[0]\n",
    "          reset_sample_state.run()\n",
    "          for _ in range(5779):\n",
    "            prediction = sample_prediction.eval({sample_input: feed})\n",
    "            feed = sample(prediction)\n",
    "            sentence += characters(feed)[0]\n",
    "          print(sentence)\n",
    "        print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl4vtmFfa5nn"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "You might have noticed that the definition of the LSTM cell involves 4 matrix multiplications with the input, and 4 matrix multiplications with the output. Simplify the expression by using a single matrix multiply for each, and variables that are 4 times larger.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4eErTCTybtph"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "We want to train a LSTM over bigrams, that is pairs of consecutive characters like 'ab' instead of single characters like 'a'. Since the number of possible bigrams is large, feeding them directly to the LSTM using 1-hot encodings will lead to a very sparse representation that is very wasteful computationally.\n",
    "\n",
    "a- Introduce an embedding lookup on the inputs, and feed the embeddings to the LSTM cell instead of the inputs themselves.\n",
    "\n",
    "b- Write a bigram-based LSTM, modeled on the character LSTM above.\n",
    "\n",
    "c- Introduce Dropout. For best practices on how to use Dropout in LSTMs, refer to this [article](http://arxiv.org/abs/1409.2329).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5tapX3kpcqZ"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "\n",
    "(difficult!)\n",
    "\n",
    "Write a sequence-to-sequence LSTM which mirrors all the words in a sentence. For example, if your input is:\n",
    "\n",
    "    the quick brown fox\n",
    "    \n",
    "the model should attempt to output:\n",
    "\n",
    "    eht kciuq nworb xof\n",
    "    \n",
    "Refer to the lecture on how to put together a sequence-to-sequence model, as well as [this article](http://arxiv.org/abs/1409.3215) for best practices.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files so far: 100\n",
      "Files so far: 200\n",
      "Files so far: 300\n",
      "Files so far: 400\n",
      "Files so far: 500\n",
      "Files so far: 600\n",
      "Files so far: 700\n",
      "Files so far: 800\n",
      "Files so far: 900\n",
      "Files so far: 1000\n",
      "Files so far: 1100\n",
      "Files so far: 1200\n",
      "Files so far: 1300\n",
      "Files so far: 1400\n",
      "Files so far: 1500\n",
      "Files so far: 1600\n",
      "Files so far: 1700\n",
      "Files so far: 1800\n",
      "Files so far: 1900\n",
      "Files so far: 2000\n",
      "Files so far: 2100\n",
      "Files so far: 2200\n",
      "Files so far: 2300\n",
      "Files so far: 2400\n",
      "Files so far: 2500\n",
      "Files so far: 2600\n",
      "Files so far: 2700\n",
      "Files so far: 2800\n",
      "Files so far: 2900\n",
      "Files so far: 3000\n",
      "Files so far: 3100\n",
      "Files so far: 3200\n",
      "Files so far: 3300\n",
      "Files so far: 3400\n",
      "Files so far: 3500\n",
      "Files so far: 3600\n",
      "Files so far: 3700\n",
      "Files so far: 3800\n",
      "Files so far: 3900\n",
      "Files so far: 4000\n",
      "Files so far: 4100\n",
      "Files so far: 4200\n",
      "Files so far: 4300\n",
      "Files so far: 4400\n",
      "Files so far: 4500\n",
      "Files so far: 4600\n",
      "Files so far: 4700\n",
      "Files so far: 4800\n",
      "Files so far: 4900\n",
      "Files so far: 5000\n",
      "Files so far: 5100\n",
      "Files so far: 5200\n",
      "Files so far: 5300\n",
      "Files so far: 5400\n",
      "Files so far: 5500\n",
      "Files so far: 5600\n",
      "Files so far: 5700\n",
      "Files so far: 5800\n",
      "Files so far: 5900\n",
      "Files so far: 6000\n",
      "Files so far: 6100\n",
      "Files so far: 6200\n",
      "Files so far: 6300\n",
      "Files so far: 6400\n",
      "Files so far: 6500\n",
      "Files so far: 6600\n",
      "Files so far: 6700\n",
      "Files so far: 6800\n",
      "Files so far: 6900\n",
      "Files so far: 7000\n",
      "Files so far: 7100\n",
      "Files so far: 7200\n",
      "Files so far: 7300\n",
      "Files so far: 7400\n",
      "Files so far: 7500\n",
      "Files so far: 7600\n",
      "Files so far: 7700\n",
      "Files so far: 7800\n",
      "Files so far: 7900\n",
      "Files so far: 8000\n",
      "Files so far: 8100\n",
      "Files so far: 8200\n",
      "Files so far: 8300\n",
      "Files so far: 8400\n",
      "Files so far: 8500\n",
      "Files so far: 8600\n",
      "Files so far: 8700\n",
      "Files so far: 8800\n",
      "Files so far: 8900\n",
      "Files so far: 9000\n",
      "Files so far: 9100\n",
      "Files so far: 9200\n",
      "Files so far: 9300\n",
      "Files so far: 9400\n",
      "Files so far: 9500\n",
      "Files so far: 9600\n",
      "Files so far: 9700\n",
      "Files so far: 9800\n",
      "Files so far: 9900\n",
      "Files so far: 10000\n",
      "Files so far: 10100\n",
      "Files so far: 10200\n",
      "Files so far: 10300\n",
      "Files so far: 10400\n",
      "Files so far: 10500\n",
      "Files so far: 10600\n",
      "Files so far: 10700\n",
      "Files so far: 10800\n",
      "Files so far: 10900\n",
      "Files so far: 11000\n",
      "Files so far: 11100\n",
      "Files so far: 11200\n",
      "Files so far: 11300\n",
      "Files so far: 11400\n",
      "Files so far: 11500\n",
      "Files so far: 11600\n",
      "Files so far: 11700\n",
      "Files so far: 11800\n",
      "Files so far: 11900\n",
      "Files so far: 12000\n",
      "Files so far: 12100\n",
      "Files so far: 12200\n",
      "Files so far: 12300\n",
      "Files so far: 12400\n",
      "Files so far: 12500\n",
      "Files so far: 12600\n",
      "Files so far: 12700\n",
      "Files so far: 12800\n",
      "Files so far: 12900\n",
      "Files so far: 13000\n",
      "Files so far: 13100\n",
      "Files so far: 13200\n",
      "Files so far: 13300\n",
      "Files so far: 13400\n",
      "Files so far: 13500\n",
      "Files so far: 13600\n",
      "Files so far: 13700\n",
      "Files so far: 13800\n",
      "Files so far: 13900\n",
      "Files so far: 14000\n",
      "Files so far: 14100\n",
      "Files so far: 14200\n",
      "Files so far: 14300\n",
      "Files so far: 14400\n",
      "Files so far: 14500\n",
      "Files so far: 14600\n",
      "Files so far: 14700\n",
      "Files so far: 14800\n",
      "Files so far: 14900\n",
      "Files so far: 15000\n",
      "Files so far: 15100\n",
      "Files so far: 15200\n",
      "Files so far: 15300\n",
      "Files so far: 15400\n",
      "Files so far: 15500\n",
      "Files so far: 15600\n",
      "Files so far: 15700\n",
      "Files so far: 15800\n",
      "Files so far: 15900\n",
      "Files so far: 16000\n",
      "Files so far: 16100\n",
      "Files so far: 16200\n",
      "Files so far: 16300\n",
      "Files so far: 16400\n",
      "Files so far: 16500\n",
      "Files so far: 16600\n",
      "Files so far: 16700\n",
      "Files so far: 16800\n",
      "Files so far: 16900\n",
      "Files so far: 17000\n",
      "Files so far: 17100\n",
      "Files so far: 17200\n",
      "Files so far: 17300\n",
      "Files so far: 17400\n",
      "Files so far: 17500\n",
      "Files so far: 17600\n",
      "Files so far: 17700\n",
      "Files so far: 17800\n",
      "Files so far: 17900\n",
      "Files: 17921\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "walk_dir = \"f:/clc trunk\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open('d:/javacode.dump', 'w') as outfile:\n",
    "  for root, subdirs, files in os.walk(walk_dir):\n",
    "    for f in files:\n",
    "        if (f.endswith(\".java\")):\n",
    "            count+=1\n",
    "            if count%100==0:\n",
    "                print(\"Files so far: \" + str(count))\n",
    "            with open(root + \"/\" + f) as infile:\n",
    "                 try:\n",
    "                   for line in infile:\n",
    "                        outfile.write(line)\n",
    "                 except UnicodeDecodeError:\n",
    "                    pass\n",
    "                    \n",
    "\n",
    "print(\"Files: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "default_view": {},
   "name": "6_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
